# ğŸš€ NWK AI-Powered Image Management System

**Professional web-based image management system for ecommerce product catalogs with AI validation and real-time processing.**

![System Status](https://img.shields.io/badge/Status-Production%20Ready-green)
![Python](https://img.shields.io/badge/Python-3.8%2B-blue)
![License](https://img.shields.io/badge/License-MIT-blue)

## ğŸ¯ **What This System Does**

Intelligently finds, downloads, validates, and manages product images from South African retailers using:
- **ğŸ¤– OpenAI CLIP** for semantic image validation
- **ğŸ” SerpAPI** for intelligent image search
- **ğŸ“± Modern Web UI** with real-time updates
- **ğŸ§  Learning System** that improves over time

---

## âš¡ **Quick Start (5 Minutes)**

### **1. Clone & Setup**
```bash
git clone https://github.com/GuneevS/ScrapingLikeBoss.git
cd ScrapingLikeBoss
chmod +x SETUP.sh
./SETUP.sh
```

### **2. Configure API Key**
```bash
# Edit .env file (created by setup)
nano .env

# Add your SerpAPI key:
SERP_API_KEY=your_actual_serpapi_key_here
```
*Get free API key at: https://serpapi.com/*

### **3. Start Application**
```bash
chmod +x START.sh
./START.sh
```

### **4. Open Browser**
Navigate to: **http://localhost:8847**

---

## ğŸŒŸ **Key Features**

### **ğŸ”¥ AI-Powered Processing**
- **CLIP Validation**: Uses OpenAI's CLIP model for semantic image-text matching
- **OCR Integration**: EasyOCR extracts text from images for brand verification
- **GPU Acceleration**: Supports CUDA, Apple Silicon (MPS), and CPU
- **Learning System**: 80%+ success rate that improves over time

### **âš¡ Performance Optimized**
- **Async Processing**: 25 concurrent downloads
- **Smart Caching**: Reduces API calls by 30-50%
- **Real-time Updates**: Dashboard updates every 5 seconds
- **Batch Operations**: Process 1-100 products at once

### **ğŸ¨ Professional Web Interface**
- **Modern Dashboard**: Real-time stats and progress tracking
- **Image Review**: Click-to-enlarge with approve/decline
- **Bulk Operations**: Select multiple products for batch actions
- **Export System**: Generate Excel reports with image links

### **ğŸ§  Intelligent Search**
- **Multi-Retailer**: Shoprite, Pick n Pay, Checkers, Makro, etc.
- **Variant Aware**: Handles flavors, sizes, and product variations
- **Confidence Scoring**: AI rates image-product match quality
- **Retailer Prioritization**: Learns which sources work best

---

## ğŸ“‹ **System Requirements**

### **Minimum:**
- **OS**: macOS, Linux, Windows
- **Python**: 3.8+
- **RAM**: 4GB (8GB recommended for CLIP)
- **Storage**: 2GB for dependencies + your images

### **Required Services:**
- **SerpAPI Key**: For Google Images search (free tier available)

### **Optional but Recommended:**
- **GPU**: NVIDIA (CUDA) or Apple Silicon (MPS) for faster processing
- **SSD Storage**: For better performance with large image sets

---

## ğŸ›  **Installation Guide**

### **Option 1: Automated Setup (Recommended)**
```bash
# Clone repository
git clone https://github.com/GuneevS/ScrapingLikeBoss.git
cd ScrapingLikeBoss

# Run setup script
./SETUP.sh

# Edit configuration
nano .env  # Add your SerpAPI key

# Start application
./START.sh
```

### **Option 2: Manual Setup**
```bash
# Create directories
mkdir -p data output/{approved,pending,declined} exports logs uploads

# Create virtual environment
python3 -m venv .venv
source .venv/bin/activate

# Install dependencies
pip install -r requirements.txt

# Create .env file
cp .env.example .env  # Then edit with your API key

# Initialize database
python3 -c "from database import ImageDatabase; ImageDatabase('data/products.db')"

# Start application
python3 app.py
```

---

## ğŸš€ **Usage Guide**

### **Basic Workflow:**
1. **Import** â†’ Upload Excel file with product data
2. **Process** â†’ AI finds and downloads images
3. **Review** â†’ Approve/decline images with confidence scores
4. **Export** â†’ Download Excel with image links

### **Web Interface:**
- **Dashboard**: `http://localhost:8847/` - Stats and processing
- **Import**: `http://localhost:8847/import` - Upload Excel files  
- **Review**: `http://localhost:8847/review` - Approve/decline images
- **Export**: `http://localhost:8847/export` - Download results

### **Excel File Format:**
Your Excel file should contain columns like:
- `Variant_SKU` (required)
- `Title`, `Brand` (for search)
- `Variant_Barcode` (improves accuracy)
- `Variant_Title`, `Variant_option` (for variants)

---

## âš™ï¸ **Configuration**

### **Main Settings (`config.yaml`):**
```yaml
search:
  serp_api_key: "${SERP_API_KEY}"
  max_results: 10
  results_per_query: 5

network:
  concurrency: 25  # Concurrent downloads
  timeout: 15

clip:
  model: "ViT-B/32"
  thresholds:
    auto_approve: 70    # Auto-approve above 70%
    needs_review: 40    # Review between 40-70%
    auto_reject: 25     # Auto-reject below 25%

image:
  size: 1000          # Max dimension
  max_kb: 200         # Max file size
  format: "jpg"
```

### **Environment Variables (`.env`):**
```bash
SERP_API_KEY=your_serpapi_key_here
CLIP_CONFIDENCE_THRESHOLD=0.65
BATCH_SIZE=10
MAX_WORKERS=5
```

---

## ğŸ”§ **Troubleshooting**

### **Common Issues:**

**â“ "No module named 'database'" Error:**
```bash
# Install dependencies
pip install -r requirements.txt

# Or run setup script
./SETUP.sh
```

**â“ "SerpAPI key not found" Error:**
```bash
# Edit .env file
nano .env

# Add your key:
SERP_API_KEY=your_actual_key_here
```

**â“ Database/Permission Errors:**
```bash
# Reset and recreate
rm -rf data/
./SETUP.sh
```

**â“ CLIP Model Download Issues:**
```bash
# Ensure good internet connection and sufficient RAM
# Model downloads ~2GB on first use
# Check available space: df -h
```

**â“ Port Already in Use:**
```bash
# Kill existing processes
pkill -f "python app.py"
# Or change port in app.py
```

---

## ğŸ“Š **Performance Metrics**

### **Typical Performance:**
- **Processing Speed**: ~150 images/minute
- **Success Rate**: 80%+ with learning system
- **API Efficiency**: 30-50% reduction through caching
- **Memory Usage**: ~2-4GB (including CLIP model)

### **Optimization Tips:**
- Use GPU acceleration when available
- Increase `network.concurrency` for faster downloads
- Enable database caching with `use_db_cache: true`
- Process in smaller batches if memory constrained

---

## ğŸ—ï¸ **Architecture Overview**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Web Interface â”‚    â”‚  Image Processor â”‚    â”‚   AI Validation â”‚
â”‚                 â”‚    â”‚                  â”‚    â”‚                 â”‚
â”‚  â€¢ Dashboard    â”‚â—„â”€â”€â–ºâ”‚  â€¢ Search Engine â”‚â—„â”€â”€â–ºâ”‚  â€¢ CLIP Model   â”‚
â”‚  â€¢ Review UI    â”‚    â”‚  â€¢ Downloader    â”‚    â”‚  â€¢ OCR Engine   â”‚
â”‚  â€¢ Export       â”‚    â”‚  â€¢ Cache System  â”‚    â”‚  â€¢ Learning AI  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                        â”‚                        â”‚
         â–¼                        â–¼                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    Database     â”‚    â”‚   File Storage   â”‚    â”‚   External APIs â”‚
â”‚                 â”‚    â”‚                  â”‚    â”‚                 â”‚
â”‚  â€¢ Products     â”‚    â”‚  â€¢ Images        â”‚    â”‚  â€¢ SerpAPI      â”‚
â”‚  â€¢ Metadata     â”‚    â”‚  â€¢ Exports       â”‚    â”‚  â€¢ Google       â”‚
â”‚  â€¢ Learning     â”‚    â”‚  â€¢ Logs          â”‚    â”‚  â€¢ Retailers    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ¤ **Contributing**

### **Development Setup:**
```bash
# Clone and setup development environment
git clone https://github.com/GuneevS/ScrapingLikeBoss.git
cd ScrapingLikeBoss
./SETUP.sh

# Install development dependencies
pip install -r requirements.txt
pip install pytest black flake8

# Run tests
python -m pytest tests/
```

### **Code Structure:**
- `app.py` - Flask web application
- `image_processor.py` - Core image processing engine
- `database.py` - Database operations
- `clip_validator.py` - AI validation system
- `learning_system.py` - Machine learning feedback
- `src/` - Utility modules (downloader, scraper, etc.)

---

## ğŸ“„ **License**

This project is licensed under the MIT License - see the LICENSE file for details.

---

## ğŸ†˜ **Support**

### **Documentation:**
- **Full Docs**: `DOCUMENTATION.md`
- **Architecture**: `docs/ARCHITECTURE.md`
- **Issue Tracker**: `ISSUE_TRACKER.md`

### **Getting Help:**
1. Check the troubleshooting section above
2. Review the logs in `logs/` directory
3. Open an issue on GitHub with error details

---

## ğŸ‰ **Ready to Use!**

After setup, your NWK Image Management System will be running at:
**http://localhost:8847**

**Happy image processing!** ğŸš€
